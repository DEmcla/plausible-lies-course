# CSCI 247: Plausible Lies

**Evaluating AI and the Tools That Shape What We Know**

A course teaching students to critically evaluate AI and digital tools—not build them. No prerequisites, no coding required. Open to all majors. Fulfills Tier II Science & Technology requirement.

---

## What This Course Is

Students graduate without knowing how to evaluate the tools they'll use for the rest of their careers. This course teaches a transferable framework for evaluating any technology—current or future—by asking the right questions:

- **Function**: Does it do what it claims?
- **Data**: What's it trained on? What does it collect?
- **Failures**: Where does it break? How badly?
- **Access**: Who can use this? Who's excluded?
- **Terms**: What am I agreeing to?
- **Broader Impact**: What happens at scale? Who benefits? Who's harmed?

The framework predates AI and will outlast current tools. AI is just our test case.

---

## Tier II Science & Technology Alignment

This course fulfills MCLA's Tier II Science & Technology requirement. Each learning outcome maps directly to a Tier II outcome:

| Learning Outcome | Tier II Outcome |
|------------------|-----------------|
| Explain how different AI models work and select appropriate tools for specific tasks | Content Knowledge |
| Apply a systematic evaluation framework to assess any technology's claims, limitations, and trade-offs | Problem Solving |
| Communicate findings through professional documents, structured reports, and clear presentations | Communication |
| Interpret and critique data visualizations, including AI-generated graphs, for statistical validity and misleading representations | Graphs & Visualization |
| Design and conduct controlled comparisons of AI tools, documenting methodology and drawing evidence-based conclusions | Scientific Practices |
| Evaluate source reliability across AI outputs, training data claims, and technical documentation | Source Evaluation |

---

## Learning Outcomes

Students completing this course will be able to:

1. Explain how different AI models work and select appropriate tools for specific tasks
2. Apply a systematic evaluation framework to assess any technology's claims, limitations, and trade-offs
3. Communicate findings through professional documents, structured reports, and clear presentations
4. Interpret and critique data visualizations, including AI-generated graphs, for statistical validity and misleading representations
5. Design and conduct controlled comparisons of AI tools, documenting methodology and drawing evidence-based conclusions
6. Evaluate source reliability across AI outputs, training data claims, and technical documentation

---

## Course Content

### Unit 1: Foundations (Weeks 1-3)
- What is AI? Types of models: LLMs, image generators, classifiers, recommendation systems
- How training works (conceptually): data in, patterns out, no understanding
- The evaluation framework introduction: Function, Data, Failures, Access, Terms, Impact

### Unit 2: Testing Claims (Weeks 4-6)
- Designing controlled comparisons: same prompt, multiple models
- Documenting methodology: what you did, what you found, what it means
- Reproducibility: why "it worked for me" isn't evidence

### Unit 3: Visualizations & Data (Weeks 7-9)
- How AI generates graphs and charts
- Spotting BS: misleading axes, cherry-picked data, statistical insignificance
- Evaluating published benchmarks and performance claims

### Unit 4: Communication & Synthesis (Weeks 10-12)
- Professional documentation: structuring findings, writing for audiences
- Practical tools: Word styles, accessibility, version control
- Presenting technical evaluations to non-technical audiences

### Unit 5: Application (Weeks 13-14)
- Tool Adaptability Exercise (final assessment)
- Framework applied to novel/emerging tools

---

## Course Versions

### In-Person (14 weeks)
Full semester course with twice-weekly meetings. Includes hands-on activities, presentations, and peer discussions.

**Files:**
- `in-person/CSCI247_Plausible_Lies_Student_Packet.docx` — Student-facing syllabus, assignments, framework
- `in-person/CSCI247_Plausible_Lies_Instructor_Packet.docx` — Week-by-week lesson plans, activities, facilitation notes

### Online (6 weeks, Summer)
Accelerated asynchronous online version for summer sessions. Fully redesigned for online delivery.

**Files:**
- `online/CSCI247_Plausible_Lies_ONLINE_Student_Packet.docx` — Technical requirements, weekly structure, assignments
- `online/CSCI247_Plausible_Lies_ONLINE_Instructor_Packet.docx` — Video production guide, discussion facilitation, time management

### Supporting Documents
- `docs/CSCI247_Plausible_Lies_Curriculum_Brief.docx` — One-page overview for curriculum committees
- `docs/plans/2026-01-15-tier2-alignment-design.md` — Tier II alignment design document

---

## Course Parameters

| Parameter | In-Person | Online |
|-----------|-----------|--------|
| Duration | 14 weeks | 6 weeks |
| Meetings | 2x/week, 75 min | Asynchronous |
| Enrollment Cap | 25 | 20 (10 first run) |
| Prerequisites | None | None |
| Coding Required | No | No |

---

## Assessments

| Assessment | Weight | Tier II Outcomes |
|------------|--------|------------------|
| AI Tool Audit | 25% | Content Knowledge, Problem Solving, Source Evaluation |
| Personal Security Audit | 25% | Problem Solving, Communication |
| Participation/Weekly Work | 20% | Scientific Practices, Graphs & Visualization |
| Tool Adaptability Exercise | 30% | All (integrated capstone) |

---

## Key Design Principles

**Framework, not tools.** Specific tools are examples, not content. The evaluation framework applies to any technology.

**Judgment, not compliance.** Assessments reward thoughtful analysis of trade-offs, not correct answers.

**Historical context.** AI is just the current instance of a long-standing problem: computational systems that shape meaning, authority, and trust—often invisibly.

**Durability by design.** Examples refresh annually; principles persist.

---

## Practical Skills Included

While evaluation is the focus, students also build:

- Word: Styles, track changes, accessibility, templates
- Excel: Data organization, formulas, failure modes (optional in online version)
- Security: Password managers, MFA, privacy settings
- Collaboration: Async communication, file management, version control

---

## For Instructors

The instructor packets include:

- Detailed week-by-week lesson plans
- Minute-by-minute class timings (in-person)
- Discussion facilitation guidance (online)
- Materials checklists
- Sample activities and scenarios
- Grading rubrics
- Time management recommendations
- First-day scripts for addressing the "CSCI" barrier

---

## Relationship to "Calling Bullshit"

This course complements Bergstrom & West's "Calling Bullshit" (statistical and media literacy) by addressing a different mechanism: systems that generate plausible content without understanding. Different mechanism, same epistemological problem.

---

## License

[Add your preferred license]

---

## Contributing

[Add contribution guidelines if desired]

---

## Contact

[Add contact information]
