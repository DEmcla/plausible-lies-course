<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>CSCI 247: Course Materials</title>
    <style>
        body {
            font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, "Helvetica Neue", Arial, sans-serif;
            line-height: 1.6;
            max-width: 900px;
            margin: 0 auto;
            padding: 20px;
            color: #333;
        }
        h1 {
            color: #1a5276;
            border-bottom: 3px solid #1a5276;
            padding-bottom: 10px;
        }
        h2 {
            color: #2874a6;
            border-bottom: 1px solid #ddd;
            padding-bottom: 5px;
            margin-top: 40px;
        }
        h3 {
            color: #1a5276;
            margin-top: 25px;
        }
        .intro {
            background-color: #f8f9fa;
            border-left: 4px solid #2874a6;
            padding: 15px;
            margin: 15px 0;
        }
        .resource {
            margin: 15px 0;
            padding: 15px;
            background-color: #f9f9f9;
            border-radius: 5px;
        }
        .resource h4 {
            margin: 0 0 8px 0;
            color: #1a5276;
        }
        .resource p {
            margin: 5px 0;
            font-size: 0.95em;
        }
        .resource .type {
            display: inline-block;
            padding: 2px 8px;
            background-color: #2874a6;
            color: white;
            font-size: 0.75em;
            border-radius: 3px;
            margin-right: 8px;
        }
        .resource .type.video {
            background-color: #c0392b;
        }
        .resource .type.book {
            background-color: #27ae60;
        }
        .resource .type.tool {
            background-color: #8e44ad;
        }
        .resource a {
            color: #2874a6;
            text-decoration: none;
        }
        .resource a:hover {
            text-decoration: underline;
        }
        .note {
            background-color: #fff9e6;
            border-left: 4px solid #f0ad4e;
            padding: 15px;
            margin: 15px 0;
        }
        .validated {
            color: #27ae60;
            font-size: 0.85em;
        }
        ul {
            margin: 10px 0;
        }
        li {
            margin: 5px 0;
        }
    </style>
</head>
<body>

<h1>Course Materials</h1>

<div class="intro">
    <p>All readings and resources for CSCI 247: Confident Uncertainty. Organized by unit. All links verified as of January 2026.</p>
    <p>No textbook required. All materials are freely available online.</p>
</div>

<h2>Foundational Resources (All Units)</h2>

<div class="resource">
    <h4><span class="type">Website</span> <a href="https://callingbullshit.org/" target="_blank">Calling Bullshit: Data Reasoning in a Digital World</a></h4>
    <p>Carl Bergstrom & Jevin West, University of Washington. Course materials, videos, and case studies on critical evaluation of data claims. Complements this course's focus on AI.</p>
    <p class="validated">✓ Verified</p>
</div>

<div class="resource">
    <h4><span class="type book">Book</span> <a href="https://callingbullshit.org/book.html" target="_blank">Calling Bullshit: The Art of Skepticism in a Data-Driven World</a></h4>
    <p>Bergstrom & West (2020). Optional but recommended. Covers statistical literacy and media claims—different mechanism than AI, same epistemological problem.</p>
</div>

<h2>Unit 1: Foundations (Weeks 1-3)</h2>
<p><em>Topics: AI model types, how training works, evaluation framework introduction</em></p>

<h3>How AI Models Work</h3>

<div class="resource">
    <h4><span class="type">Article</span> <a href="https://www.ibm.com/think/topics/large-language-models" target="_blank">What Are Large Language Models (LLMs)?</a></h4>
    <p>IBM Think. Clear explanation of transformer architecture, training process, and limitations. Good starting point for understanding LLMs conceptually.</p>
    <p class="validated">✓ Verified</p>
</div>

<div class="resource">
    <h4><span class="type video">Video</span> <a href="https://mitsloanedtech.mit.edu/ai/basics/how-chatgpt-works-a-non-technical-primer/" target="_blank">How ChatGPT Works: A Non-Technical Primer</a></h4>
    <p>MIT Sloan, Rama Ramakrishnan. Video explanation of "predict the next word" mechanism, training data, and limitations. Accessible for non-technical audiences.</p>
    <p class="validated">✓ Verified</p>
</div>

<div class="resource">
    <h4><span class="type">Article</span> <a href="https://writings.stephenwolfram.com/2023/02/what-is-chatgpt-doing-and-why-does-it-work/" target="_blank">What Is ChatGPT Doing … and Why Does It Work?</a></h4>
    <p>Stephen Wolfram. Deep dive into LLM mechanics with visualizations. More technical—good for students who want to understand the "how" in detail.</p>
    <p class="validated">✓ Verified</p>
</div>

<div class="resource">
    <h4><span class="type">Article</span> <a href="https://aws.amazon.com/what-is/large-language-model/" target="_blank">What is LLM? Large Language Models Explained</a></h4>
    <p>AWS. Overview of LLM capabilities, use cases, and how they differ from traditional software.</p>
</div>

<h3>Types of AI Models</h3>

<div class="resource">
    <h4><span class="type">Article</span> <a href="https://zapier.com/blog/types-of-ai-models/" target="_blank">What are AI models? Types of AI models</a></h4>
    <p>Zapier. Practical overview of different AI model types: LLMs, image generators, classifiers, recommendation systems. Good for "right tool for right job" discussions.</p>
</div>

<div class="resource">
    <h4><span class="type">Article</span> <a href="https://airbyte.com/data-engineering-resources/types-of-ai-models" target="_blank">Types of AI Models: Your Ultimate Guide</a></h4>
    <p>Airbyte. Comprehensive breakdown of ML models, deep learning, generative AI. More technical but thorough.</p>
</div>

<h3>Training Data and Bias</h3>

<div class="resource">
    <h4><span class="type">Article</span> <a href="https://www.ibm.com/think/topics/ai-bias" target="_blank">What Is AI Bias?</a></h4>
    <p>IBM Think. Explains ten types of AI bias, real-world examples (healthcare, hiring, policing), and prevention strategies.</p>
    <p class="validated">✓ Verified</p>
</div>

<div class="resource">
    <h4><span class="type">Article</span> <a href="https://www.sap.com/resources/what-is-ai-bias" target="_blank">What is AI bias? Causes, effects, and mitigation strategies</a></h4>
    <p>SAP. Overview of bias sources in data collection, labeling, and model design.</p>
</div>

<div class="resource">
    <h4><span class="type">Article</span> <a href="https://www.psu.edu/news/bellisario-college-communications/story/most-users-cannot-identify-ai-bias-even-training-data" target="_blank">Most users cannot identify AI bias, even in training data</a></h4>
    <p>Penn State Research. Study showing people fail to notice systematic bias in AI training data. Good case study for class discussion.</p>
</div>

<h2>Unit 2: Testing Claims (Weeks 4-6)</h2>
<p><em>Topics: Controlled comparisons, methodology documentation, reproducibility</em></p>

<h3>AI Reproducibility</h3>

<div class="resource">
    <h4><span class="type">Article</span> <a href="https://research.aimultiple.com/reproducible-ai/" target="_blank">Reproducible AI: Why it Matters & How to Improve it</a></h4>
    <p>AIMultiple. Overview of the reproducibility crisis in AI—only 30% of AI research is reproducible. Explains why same prompts give different results.</p>
</div>

<div class="resource">
    <h4><span class="type">Article</span> <a href="https://www.sandgarden.com/learn/reproducibility" target="_blank">When Experiments Go Awry: Understanding Reproducibility in AI</a></h4>
    <p>Sandgarden. Explains why LLMs are inherently probabilistic and how temperature/sampling affects output consistency.</p>
</div>

<div class="resource">
    <h4><span class="type">Article</span> <a href="https://www.cos.io/blog/from-open-science-to-ai-benchmarking-llms-on-reproducibility-robustness-and-replication" target="_blank">From Open Science to AI: Benchmarking LLMs on Reproducibility</a></h4>
    <p>Center for Open Science. Applies scientific reproducibility standards to AI systems.</p>
</div>

<h3>Scientific Method Connections</h3>

<div class="resource">
    <h4><span class="type">Syllabus</span> <a href="https://callingbullshit.org/syllabus.html" target="_blank">Calling Bullshit Syllabus</a></h4>
    <p>Full 12-week curriculum covering causal reasoning, statistical misconceptions, and debunking strategies. Use selected modules to complement Unit 2.</p>
    <p class="validated">✓ Verified</p>
</div>

<h2>Unit 3: Visualizations & Data (Weeks 7-9)</h2>
<p><em>Topics: AI-generated graphs, spotting misleading visualizations, benchmark evaluation</em></p>

<h3>Misleading Visualizations</h3>

<div class="resource">
    <h4><span class="type">Article</span> <a href="https://www.thoughtspot.com/data-trends/data-visualization/how-to-identify-misleading-graphs-and-charts" target="_blank">How to Identify Misleading Graphs and Charts</a></h4>
    <p>ThoughtSpot. Five common deceptive techniques: manipulated Y-axis, dual axes, cherry-picked data, non-uniform scales, incomplete labels. Includes verification checklist.</p>
    <p class="validated">✓ Verified</p>
</div>

<div class="resource">
    <h4><span class="type">Article</span> <a href="https://www.luzmo.com/blog/bad-data-visualization" target="_blank">Bad Data Visualization: 9 Examples to Learn From</a></h4>
    <p>Luzmo. Real-world examples of misleading graphs with explanations of what went wrong.</p>
</div>

<div class="resource">
    <h4><span class="type">Article</span> <a href="https://www.owox.com/blog/articles/bad-data-visualization-examples" target="_blank">Bad Data Visualization Examples to Avoid</a></h4>
    <p>OWOX. Gallery of visualization failures with analysis.</p>
</div>

<div class="resource">
    <h4><span class="type tool">Tool</span> <a href="https://callingbullshit.org/tools.html" target="_blank">Calling Bullshit: Tools</a></h4>
    <p>Bergstrom & West. Tools for analyzing misleading axes and proportional ink principles.</p>
</div>

<h3>AI Benchmarks and Evaluation</h3>

<div class="resource">
    <h4><span class="type">Article</span> <a href="https://www.oii.ox.ac.uk/news-events/study-identifies-weaknesses-in-how-ai-systems-are-evaluated/" target="_blank">Study identifies weaknesses in how AI systems are evaluated</a></h4>
    <p>Oxford Internet Institute. Research showing ~50% of AI benchmarks fail to define what they're measuring. Explains why benchmark claims should be scrutinized.</p>
</div>

<div class="resource">
    <h4><span class="type">Article</span> <a href="https://www.nature.com/articles/d41586-025-02462-5" target="_blank">Is your AI benchmark lying to you?</a></h4>
    <p>Nature. Overview of benchmark problems: data contamination, brittle performance, unsupported claims.</p>
</div>

<div class="resource">
    <h4><span class="type">Article</span> <a href="https://blog.sshh.io/p/understanding-ai-benchmarks" target="_blank">Understanding AI Benchmarks</a></h4>
    <p>Shrivu Shankar. Accessible explanation of what benchmarks measure and their limitations.</p>
</div>

<div class="resource">
    <h4><span class="type">Article</span> <a href="https://www.theregister.com/2025/11/07/measuring_ai_models_hampered_by/" target="_blank">AI benchmarks hampered by bad science</a></h4>
    <p>The Register. News coverage of benchmark validity research.</p>
</div>

<h2>Unit 4: Communication & Synthesis (Weeks 10-12)</h2>
<p><em>Topics: Professional documentation, presenting findings, technical writing</em></p>

<h3>Writing for Non-Technical Audiences</h3>

<div class="resource">
    <h4><span class="type">Article</span> <a href="https://document360.com/blog/technical-writing-for-non-technical-audience/" target="_blank">Effective Technical Writing for Non-Technical Audiences</a></h4>
    <p>Document360. Ten techniques for simplifying complex information: know your audience, focus on outcomes, use analogies, test with non-technical reviewers.</p>
    <p class="validated">✓ Verified</p>
</div>

<div class="resource">
    <h4><span class="type">Article</span> <a href="https://www.writing-skills.com/knowledge-hub/how-to-write-for-a-non-technical-audience/" target="_blank">How to write for a non-technical audience</a></h4>
    <p>Emphasis. Addresses the "curse of knowledge" and strategies for overcoming it.</p>
</div>

<div class="resource">
    <h4><span class="type">Article</span> <a href="https://www.archbee.com/blog/technical-writing-non-technical-audience" target="_blank">Technical Writer Tips: Optimizing Your Writing for Non-Technical Audience</a></h4>
    <p>Archbee. Practical tips for testing documentation with non-expert readers.</p>
</div>

<h3>Writing Methodology Sections</h3>

<div class="resource">
    <h4><span class="type">Guide</span> <a href="https://guides.lib.uci.edu/c.php?g=334338&p=2249905" target="_blank">Methods - Writing a Scientific Paper</a></h4>
    <p>UC Irvine Library. How to write methods sections that enable reproducibility.</p>
</div>

<div class="resource">
    <h4><span class="type">Guide</span> <a href="https://libguides.usc.edu/writingguide/methodology" target="_blank">The Methodology - Organizing Your Social Sciences Research Paper</a></h4>
    <p>USC Libraries. Comprehensive guide to methodology sections including structure, justification, and what to avoid.</p>
</div>

<div class="resource">
    <h4><span class="type">Article</span> <a href="https://pmc.ncbi.nlm.nih.gov/articles/PMC10676260/" target="_blank">How to Write the Methods Section of a Research Manuscript</a></h4>
    <p>PMC/NIH. Academic guide to methods writing with examples.</p>
</div>

<h2>Unit 5: Application (Weeks 13-14)</h2>
<p><em>Topics: Tool adaptability exercise, framework application to novel tools</em></p>

<div class="note">
    <p>Unit 5 focuses on applying skills from Units 1-4 to a novel tool. No new readings assigned. Students should revisit relevant materials from earlier units as needed for their final assessment.</p>
</div>

<h2>ACM Digital Library (Requires MCLA Access)</h2>

<div class="note">
    <p>Access these papers through the <a href="https://dl.acm.org/" target="_blank">ACM Digital Library</a> using your MCLA credentials. More rigorous, peer-reviewed research for students who want to go deeper.</p>
</div>

<h3>Misleading Visualizations (Unit 3)</h3>

<div class="resource">
    <h4><span class="type">Paper</span> <a href="https://dl.acm.org/doi/10.1145/3544548.3580910" target="_blank">Misleading Beyond Visual Tricks: How People Actually Lie with Charts</a></h4>
    <p>CHI 2023. Analysis of 9,958 COVID-related data visualizations on Twitter. Key finding: violations of design guidelines are NOT the dominant way people mislead—introduces "vulnerable visualizations" concept.</p>
</div>

<div class="resource">
    <h4><span class="type">Paper</span> <a href="https://dl.acm.org/doi/10.1145/3613904.3642448" target="_blank">"Yeah, this graph doesn't show that": Analysis of Online Engagement with Misleading Data Visualizations</a></h4>
    <p>CHI 2024. Shows that pro- and anti-mask communities used identical visualizations to argue opposing views. Misleadingness is often viewer-dependent, not objective.</p>
</div>

<div class="resource">
    <h4><span class="type">Paper</span> <a href="https://dl.acm.org/doi/10.1145/3544548.3581406" target="_blank">CALVI: Critical Thinking Assessment for Literacy in Visualizations</a></h4>
    <p>CHI 2023. Framework for assessing ability to identify "misleaders"—decisions in visualization construction that lead to unsupported conclusions.</p>
</div>

<div class="resource">
    <h4><span class="type">Paper</span> <a href="https://dl.acm.org/doi/10.1145/3491102.3502138" target="_blank">Annotating Line Charts for Addressing Deception</a></h4>
    <p>CHI 2022. Tool for detecting distortions in line charts. Useful for understanding automated approaches to visualization evaluation.</p>
</div>

<h3>AI Evaluation & Benchmarks (Unit 3)</h3>

<div class="resource">
    <h4><span class="type">Paper</span> <a href="https://dl.acm.org/doi/full/10.1145/3641289" target="_blank">A Survey on Evaluation of Large Language Models</a></h4>
    <p>ACM TIST. Comprehensive survey of LLM evaluation methods, benchmark limitations, and the challenge of measuring open-ended task performance.</p>
</div>

<div class="resource">
    <h4><span class="type">Article</span> <a href="https://cacm.acm.org/news/how-do-you-measure-ai/" target="_blank">How Do You Measure AI?</a></h4>
    <p>Communications of the ACM. Overview of why current AI benchmarks are inadequate—saturation, data contamination, self-reporting problems.</p>
</div>

<div class="resource">
    <h4><span class="type">Article</span> <a href="https://cacm.acm.org/blogcacm/benchmarks-for-ai-in-software-engineering/" target="_blank">Benchmarks for AI in Software Engineering</a></h4>
    <p>CACM Blog. Why HumanEval and similar coding benchmarks don't represent real software engineering work.</p>
</div>

<h3>LLM Hallucinations & Limitations (Unit 1)</h3>

<div class="resource">
    <h4><span class="type">Paper</span> <a href="https://dl.acm.org/doi/10.1145/3703155" target="_blank">A Survey on Hallucination in Large Language Models: Principles, Taxonomy, Challenges</a></h4>
    <p>ACM TOIS. Comprehensive taxonomy of hallucination types, causes (including bias), and why RAG doesn't fully solve the problem.</p>
</div>

<div class="resource">
    <h4><span class="type">Article</span> <a href="https://queue.acm.org/detail.cfm?id=3688007" target="_blank">GPTs and Hallucination: Why do large language models hallucinate?</a></h4>
    <p>ACM Queue. Accessible explanation of when LLMs hallucinate—limited training data, controversial topics, lack of consensus.</p>
</div>

<div class="resource">
    <h4><span class="type">Paper</span> <a href="https://dl.acm.org/doi/10.1145/3613904.3642428" target="_blank">HILL: A Hallucination Identifier for Large Language Models</a></h4>
    <p>CHI 2024. Research on user overreliance on LLMs and tools for identifying hallucinations. Key insight: systems won't be hallucination-free "in the near future."</p>
</div>

<div class="resource">
    <h4><span class="type">Paper</span> <a href="https://dl.acm.org/doi/10.1145/3571730" target="_blank">Survey of Hallucination in Natural Language Generation</a></h4>
    <p>ACM Computing Surveys. Technical deep dive into exposure bias, parametric knowledge, and other hallucination contributors.</p>
</div>

<h2>Supplementary Resources</h2>

<h3>AI Ethics and Governance</h3>

<div class="resource">
    <h4><span class="type">Article</span> <a href="https://mitsloanedtech.mit.edu/ai/basics/addressing-ai-hallucinations-and-bias/" target="_blank">Addressing AI Hallucinations and Bias</a></h4>
    <p>MIT Sloan. Overview of hallucination problem and bias mitigation.</p>
</div>

<div class="resource">
    <h4><span class="type">Article</span> <a href="https://www.chapman.edu/ai/bias-in-ai.aspx" target="_blank">Bias in AI</a></h4>
    <p>Chapman University. Educational overview with examples.</p>
</div>

<h3>Wikipedia (Reference)</h3>

<div class="resource">
    <h4><span class="type">Reference</span> <a href="https://en.wikipedia.org/wiki/Large_language_model" target="_blank">Large language model - Wikipedia</a></h4>
    <p>Background reference. Students should evaluate this source using course framework.</p>
</div>

<div class="resource">
    <h4><span class="type">Reference</span> <a href="https://en.wikipedia.org/wiki/ChatGPT" target="_blank">ChatGPT - Wikipedia</a></h4>
    <p>Background reference on ChatGPT history and capabilities.</p>
</div>

<hr>

<p><em>Last updated: January 2026. Links verified at time of publication. Report broken links to instructor.</em></p>

</body>
</html>
