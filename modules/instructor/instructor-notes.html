<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Instructor Notes: CSCI 247</title>
    <style>
        body { font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, sans-serif; line-height: 1.6; max-width: 800px; margin: 0 auto; padding: 20px; color: #333; }
        h1 { color: #1a5276; border-bottom: 3px solid #1a5276; padding-bottom: 10px; }
        h2 { color: #2874a6; border-bottom: 1px solid #ddd; padding-bottom: 5px; margin-top: 30px; }
        h3 { color: #1a5276; margin-top: 20px; }
        .note { background-color: #fff9e6; border-left: 4px solid #f0ad4e; padding: 15px; margin: 15px 0; }
        .tip { background-color: #d4edda; border-left: 4px solid #28a745; padding: 15px; margin: 15px 0; }
        .warning { background-color: #fce4e4; border-left: 4px solid #c0392b; padding: 15px; margin: 15px 0; }
        ul { margin: 10px 0; }
        li { margin: 8px 0; }
    </style>
</head>
<body>

<h1>Instructor Notes</h1>

<p>Guidance for teaching CSCI 247: Confident Uncertainty</p>

<h2>Course Philosophy</h2>

<p>This course teaches transferable evaluation skills, not facts about specific tools. AI tools change rapidly; the framework for evaluating them should not. Emphasize the <em>process</em> of evaluation over conclusions about any particular tool.</p>

<div class="tip">
    <p><strong>Key message to students:</strong> The goal isn't to decide if AI is "good" or "bad"—it's to develop the skills to evaluate any technology critically and make informed decisions.</p>
</div>

<h2>Module-by-Module Notes</h2>

<h3>Module 1: Foundations</h3>
<ul>
    <li>Students often arrive with strong opinions (pro or anti AI). Create space for nuance.</li>
    <li>Portfolio setup is crucial—students who skip it struggle later. Check early.</li>
    <li>The Training Data Detective activity often reveals how little companies disclose. This is the point.</li>
</ul>

<h3>Module 2: Testing Claims</h3>
<ul>
    <li>Reproducibility tests often yield different results across tools—discuss why.</li>
    <li>Students may be surprised how much prompt wording matters. Use this as a teaching moment about the limits of "AI as oracle."</li>
</ul>

<h3>Module 3: AI Tool Audit</h3>
<ul>
    <li>Approve tool choices early to avoid last-minute scrambles.</li>
    <li>Common pitfall: students summarize marketing instead of evaluating critically. Push back on this.</li>
    <li>The "Terms" component is often weakest—students don't read ToS. Encourage them to at least skim.</li>
</ul>

<h3>Module 4: Visualizations</h3>
<ul>
    <li>The Excel lesson is hands-on—make sure students actually build charts, not just read about them.</li>
    <li>"Make It Lie" often produces aha moments. Debrief thoroughly.</li>
    <li>Some students resist the idea that "accurate" charts can still mislead. Work through examples.</li>
</ul>

<h3>Module 5: Communication</h3>
<ul>
    <li>Security audit can feel personal. Remind students they control what they share.</li>
    <li>Peer review (Methodology Audit) requires clear guidelines to be constructive.</li>
</ul>

<h3>Module 6: Application</h3>
<ul>
    <li>Select the Tool Adaptability Exercise tool carefully—should be evaluable in a week, have free tier, and include some visualization component.</li>
    <li>Reveal tool Monday to give full week. Announce in advance so students know it's coming.</li>
    <li>Students may panic. Remind them they have all the skills—this is just applying them.</li>
</ul>

<h2>Common Issues</h2>

<div class="warning">
    <h3>Portfolio Problems</h3>
    <p>Students who don't set up the portfolio structure in Week 1 often struggle with Word features later. Check Checkpoint 1 carefully and provide early feedback.</p>
</div>

<div class="warning">
    <h3>Surface-Level Analysis</h3>
    <p>Many students want to describe rather than evaluate. Push for evidence-based claims, acknowledgment of trade-offs, and specific recommendations.</p>
</div>

<div class="warning">
    <h3>AI Tools Changing Mid-Course</h3>
    <p>AI tools update frequently. If a tool changes significantly mid-semester, acknowledge it and use it as a teaching moment about the evolving landscape.</p>
</div>

<h2>Tool Adaptability Exercise: Tool Selection</h2>

<p>The Week 6 tool should be:</p>
<ul>
    <li>Free tier available (or trial sufficient for evaluation)</li>
    <li>Not extensively covered in class</li>
    <li>Includes some visualization or data presentation students can evaluate</li>
    <li>Has enough public information for students to research</li>
    <li>Represents a realistic tool they might encounter professionally</li>
</ul>

<p>Past successful choices:</p>
<ul>
    <li>AI writing assistants (Jasper, Copy.ai, Writesonic)</li>
    <li>AI research tools (Elicit, Consensus)</li>
    <li>AI coding assistants (Cursor, Codeium)</li>
    <li>AI image/design tools (Canva AI, Leonardo)</li>
</ul>

<h2>Grading Notes</h2>

<ul>
    <li>Rubrics are in <code>grading-rubrics.html</code>. Use them consistently.</li>
    <li>For the AI Tool Audit, weight "Framework Application" heavily—this is the core skill.</li>
    <li>Portfolio grading focuses on the final version, but early checkpoints catch struggling students.</li>
    <li>The Tool Adaptability Exercise tests integration of all skills under time pressure—grade holistically.</li>
</ul>

<h2>Accessibility</h2>

<ul>
    <li>All HTML documents are screen-reader compatible.</li>
    <li>Color is not the only indicator of meaning in any document.</li>
    <li>Students needing accommodations should be able to complete all activities with standard accommodations.</li>
</ul>

</body>
</html>
