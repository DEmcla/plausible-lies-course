# CSCI 247 Tier II Alignment Design

## Overview

Revamp CSCI 247: Confident Uncertainty (originally "Plausible Lies", then "Confidently Uncertain") to explicitly meet MCLA Tier II Science & Technology outcomes while preserving the course's core identity as a critical evaluation course.

## Tier II Outcomes Mapping

| Tier II Outcome | How Addressed |
|-----------------|---------------|
| Content Knowledge | Conceptual understanding of AI model types, matching right tool to task |
| Problem Solving | Applying evaluation framework to analyze tools |
| Communication | Professional documents, presentations |
| Graphs & Visualization | Evaluating AI-generated graphs for validity/BS |
| Scientific Practices | Controlled comparisons: same prompt across models, document methodology |
| Source Evaluation | Core of course - the evaluation framework |

## Revised Student Learning Outcomes

1. **Explain how different AI models work** and select appropriate tools for specific tasks (Content Knowledge)

2. **Apply a systematic evaluation framework** to assess any technology's claims, limitations, and trade-offs (Problem Solving)

3. **Communicate findings** through professional documents, structured reports, and clear presentations (Communication)

4. **Interpret and critique data visualizations**, including AI-generated graphs, for statistical validity and misleading representations (Graphs & Visualization)

5. **Design and conduct controlled comparisons** of AI tools, documenting methodology and drawing evidence-based conclusions (Scientific Practices)

6. **Evaluate source reliability** across AI outputs, training data claims, and technical documentation (Source Evaluation)

## Content Units (14-Week Structure)

### Unit 1: Foundations (Weeks 1-3)
- What is AI? Types of models: LLMs, image generators, classifiers, recommendation systems
- How training works (conceptually): data in, patterns out, no understanding
- The evaluation framework introduction: Function, Data, Failures, Access, Terms, Impact
- *Maps to: Content Knowledge, Source Evaluation*

### Unit 2: Testing Claims (Weeks 4-6)
- Designing controlled comparisons: same prompt, multiple models
- Documenting methodology: what you did, what you found, what it means
- Reproducibility: why "it worked for me" isn't evidence
- *Maps to: Scientific Practices, Problem Solving*

### Unit 3: Visualizations & Data (Weeks 7-9)
- How AI generates graphs and charts
- Spotting BS: misleading axes, cherry-picked data, statistical insignificance
- Evaluating published benchmarks and performance claims
- *Maps to: Graphs & Visualization, Source Evaluation*

### Unit 4: Communication & Synthesis (Weeks 10-12)
- Professional documentation: structuring findings, writing for audiences
- Practical tools: Word styles, accessibility, version control
- Presenting technical evaluations to non-technical audiences
- *Maps to: Communication*

### Unit 5: Application (Weeks 13-14)
- Tool Adaptability Exercise (final assessment)
- Framework applied to novel/emerging tools
- *Maps to: All outcomes integrated*

## Assessment Mapping

| Assessment | Weight | Tier II Outcomes Addressed |
|------------|--------|---------------------------|
| AI Tool Audit | 25% | Content Knowledge, Problem Solving, Source Evaluation |
| Personal Security Audit | 25% | Problem Solving, Communication |
| Participation/Weekly Work | 20% | Scientific Practices, Graphs & Visualization |
| Tool Adaptability Exercise | 30% | All six (integrated capstone) |

### Assessment Adjustments

- **AI Tool Audit**: Add section requiring students to explain what type of model the tool uses and why that matters for evaluation
- **Weekly Work**: Include 2-3 structured comparison exercises (same prompt across models) and at least one AI-generated graph critique
- **Tool Adaptability Exercise**: Ensure novel tool includes visualization component students must evaluate
- **Personal Security Audit**: No changes needed

## What's Preserved

- Course structure (14 weeks in-person / 6 weeks online)
- Assessment weights (25/25/20/30)
- Core evaluation framework (Function, Data, Failures, Access, Terms, Impact)
- Practical skills (Word, security, collaboration)
- No prerequisites, no coding required

## Constraints

- Students use free tier AI tools only
- 200-level course, no prerequisites
- Not a lab course - scientific practices via structured comparisons, not experiments

## Date

2026-01-15
