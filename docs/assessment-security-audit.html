<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>CSCI 247: AI Privacy & Security Audit</title>
    <style>
        body {
            font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, "Helvetica Neue", Arial, sans-serif;
            line-height: 1.6;
            max-width: 800px;
            margin: 0 auto;
            padding: 20px;
            color: #333;
        }
        h1 {
            color: #1a5276;
            border-bottom: 3px solid #1a5276;
            padding-bottom: 10px;
        }
        h2 {
            color: #2874a6;
            border-bottom: 1px solid #ddd;
            padding-bottom: 5px;
            margin-top: 30px;
        }
        h3 {
            color: #1a5276;
            margin-top: 20px;
        }
        table {
            border-collapse: collapse;
            width: 100%;
            margin: 15px 0;
        }
        th, td {
            border: 1px solid #ddd;
            padding: 10px;
            text-align: left;
        }
        th {
            background-color: #2874a6;
            color: white;
        }
        .overview {
            background-color: #f8f9fa;
            border-left: 4px solid #2874a6;
            padding: 15px;
            margin: 15px 0;
        }
        .note {
            background-color: #fff9e6;
            border-left: 4px solid #f0ad4e;
            padding: 15px;
            margin: 15px 0;
        }
        .important {
            background-color: #fce4e4;
            border-left: 4px solid #c0392b;
            padding: 15px;
            margin: 15px 0;
        }
        .success {
            background-color: #d4edda;
            border-left: 4px solid #28a745;
            padding: 15px;
            margin: 15px 0;
        }
        ul, ol {
            margin: 10px 0;
        }
        li {
            margin: 8px 0;
        }
    </style>
</head>
<body>

<h1>AI Privacy & Security Audit</h1>

<p style="color: #666; font-size: 0.9em;"><em>Document version: 2.0 | Last updated: January 2026</em></p>

<div class="overview">
    <p><strong>Weight:</strong> 25% of final grade</p>
    <p><strong>Due:</strong> End of Week 5 (online) / Week 10 (in-person)</p>
    <p><strong>Format:</strong> Written report with evidence, 1500-2500 words</p>
</div>

<h2>Overview</h2>

<p>You will audit your own AI tool usage, evaluate what you're sharing with these tools, and make informed decisions about your privacy and security practices. This applies the course evaluation framework to your own technology use.</p>

<div class="success">
    <p><strong>Why this matters:</strong> Every time you use an AI tool, you're making trade-offs between convenience and privacy. This assignment asks you to examine those trade-offs critically and make intentional choices rather than defaulting to whatever's easiest.</p>
</div>

<h2>Requirements</h2>

<h3>Part 1: AI Tool Inventory</h3>

<p>Document all the AI tools you currently use or have accounts with:</p>

<table>
    <tr>
        <th>For Each Tool</th>
        <th>What to Examine</th>
    </tr>
    <tr>
        <td><strong>What tools?</strong></td>
        <td>ChatGPT, Claude, Gemini, Copilot, Midjourney, AI features in apps you use (Grammarly, Notion AI, etc.)</td>
    </tr>
    <tr>
        <td><strong>What have you shared?</strong></td>
        <td>Review your conversation history. What kinds of information have you put into these tools? Personal details? Work documents? Code? Sensitive questions?</td>
    </tr>
    <tr>
        <td><strong>What do the terms say?</strong></td>
        <td>Apply the framework: What does each tool's privacy policy say about your data? Is it used for training? How long is it retained? Can you delete it?</td>
    </tr>
    <tr>
        <td><strong>What settings exist?</strong></td>
        <td>What privacy controls does each tool offer? Data retention settings? Training opt-outs? Export/delete options?</td>
    </tr>
    <tr>
        <td><strong>Account security</strong></td>
        <td>Is MFA enabled? What's your password situation? Who else might have access to your account?</td>
    </tr>
</table>

<div class="note">
    <p><strong>You don't have to share sensitive details.</strong> You can say "I found conversations containing personal health questions" without revealing what those questions were.</p>
</div>

<h3>Part 2: Framework Analysis</h3>

<p>Choose your <strong>two most-used AI tools</strong> and apply the evaluation framework components relevant to privacy:</p>

<ul>
    <li><strong>Data</strong> — What data does this tool collect? What does it say about training data usage?</li>
    <li><strong>Terms</strong> — What are you actually agreeing to? Any concerning clauses?</li>
    <li><strong>Access</strong> — Who can see your data? Employees? Third parties? Law enforcement?</li>
    <li><strong>Failures</strong> — What could go wrong? Data breaches? Unintended disclosure?</li>
</ul>

<p>This is the course framework applied to your personal situation. Be specific and cite the actual policies.</p>

<h3>Part 3: Risk Assessment & Decisions</h3>

<p>For the issues you've identified:</p>

<ul>
    <li><strong>Likelihood</strong> — How probable is this risk actually being realized?</li>
    <li><strong>Severity</strong> — If it happened, how bad would it be for you personally?</li>
    <li><strong>Your decision</strong> — Given this analysis, what are you choosing to do?</li>
</ul>

<p>Be realistic. The goal isn't to stop using AI tools—it's to make informed choices about what you share and with whom.</p>

<h3>Part 4: Actions Taken</h3>

<p>Implement at least <strong>five meaningful changes</strong> based on your audit. Examples:</p>

<ul>
    <li>Enable MFA on AI tool accounts</li>
    <li>Adjust privacy/training settings (opt out of training where available)</li>
    <li>Delete conversation history you're not comfortable with</li>
    <li>Change what kinds of information you put into AI tools</li>
    <li>Set up a separate account for sensitive vs. casual use</li>
    <li>Delete accounts for AI tools you no longer use</li>
    <li>Review and revoke third-party app connections</li>
    <li>Export your data to understand what's been collected</li>
</ul>

<div class="important">
    <p><strong>Document with evidence.</strong> Screenshots (with sensitive info redacted), before/after comparisons, or other proof that you actually made changes. "I adjusted my settings" without evidence will receive reduced credit.</p>
</div>

<h3>Part 5: Reflection</h3>

<p>Conclude with:</p>

<ul>
    <li>What surprised you most about your AI tool usage and what you've been sharing?</li>
    <li>What trade-offs did you make (convenience vs. privacy)?</li>
    <li>How has this changed how you'll use AI tools going forward?</li>
    <li>What risks did you decide to accept, and why?</li>
</ul>

<h2>Document Structure</h2>

<ol>
    <li><strong>Introduction</strong> — Brief overview of your AI tool usage</li>
    <li><strong>AI Tool Inventory</strong> — What tools, what you've shared, what the terms say</li>
    <li><strong>Framework Analysis</strong> — Deep dive on your two most-used tools</li>
    <li><strong>Risk Assessment</strong> — Prioritized issues with your decisions</li>
    <li><strong>Actions Taken</strong> — What you changed, with evidence</li>
    <li><strong>Reflection</strong> — What you learned and how you'll proceed</li>
</ol>

<h2>What Makes a Strong Audit</h2>

<ul>
    <li><strong>Thoroughness</strong> — You examined multiple AI tools, not just the obvious one</li>
    <li><strong>Framework application</strong> — You actually read and analyzed the privacy policies, not just guessed</li>
    <li><strong>Realistic assessment</strong> — Neither paranoid nor dismissive about risks</li>
    <li><strong>Meaningful actions</strong> — Changes that reflect your analysis, with evidence</li>
    <li><strong>Honest reflection</strong> — Acknowledging trade-offs and what you're choosing to accept</li>
</ul>

<h2>What to Avoid</h2>

<ul>
    <li><strong>Surface-level inventory</strong> — Only listing tools without examining what you've shared</li>
    <li><strong>Skipping the policies</strong> — Making assumptions without reading the actual terms</li>
    <li><strong>No evidence</strong> — Claiming changes without proof</li>
    <li><strong>All-or-nothing thinking</strong> — "AI is evil so I'll never use it" or "privacy doesn't matter"</li>
    <li><strong>Generic advice</strong> — Repeating tips you read online vs. analyzing your specific situation</li>
</ul>

<h2>Privacy Note</h2>

<div class="note">
    <p>This assignment asks you to examine personal information. You control what you share in your submission:</p>
    <ul>
        <li>Redact account names, specific queries, or other sensitive details in screenshots</li>
        <li>Describe findings in general terms where appropriate</li>
        <li>Focus on the process and analysis, not exposing your personal data</li>
    </ul>
    <p>The goal is demonstrating that you conducted a thorough audit and made informed decisions—not revealing your secrets.</p>
</div>

<h2>Grading</h2>

<p>See the Grading Rubrics document for detailed criteria. In summary:</p>

<table>
    <tr>
        <th>Criterion</th>
        <th>Weight</th>
    </tr>
    <tr>
        <td>AI Tool Inventory (thoroughness, what you've shared)</td>
        <td>20%</td>
    </tr>
    <tr>
        <td>Framework Analysis (actual policy analysis, not guessing)</td>
        <td>25%</td>
    </tr>
    <tr>
        <td>Risk Assessment (realistic, personalized decisions)</td>
        <td>20%</td>
    </tr>
    <tr>
        <td>Actions Taken (meaningful changes with evidence)</td>
        <td>20%</td>
    </tr>
    <tr>
        <td>Reflection & Documentation (clarity, honesty, organization)</td>
        <td>15%</td>
    </tr>
</table>

<h2>Submission</h2>

<p>Submit as a Word document (.docx) or PDF through Canvas by the deadline. Include screenshots or other evidence as embedded images or an appendix.</p>

</body>
</html>
